---
title: "443 Project"
output: pdf_document
date: "2022-11-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Cleaning and Preprocessing

```{r}
df <- read.csv("Data_Group11.csv")
```

We first convert the data in to a more usable long format.
```{r}
# convert month and day to MM-DD format
singledig <- which(df$X.1 < 10)
df$day <- as.character(df$X.1)
df$day[singledig] <- paste0("0", df$day[singledig])

df$month <- rep(c("01","02","03","04", "05","06","07","08","09","10","11","12"), times=c(31,29,31,30,31,30,31,31,30,31,30,31))

df$MMDD <- paste0(df$month, "-", df$day)

# drop unnecessary columns
to_drop <- c("X", "X.1", "X.2", "X1981.2010.mean", "X1981.2010.median", "month", "day")
df <- subset(df, select=!(names(df) %in% to_drop))

# melt years to be one column
library(tidyr)
df <- pivot_longer(data=df, cols=!MMDD, names_to="year", values_to="extent")

# format year and creating a column with YY-MM-DD format
library(stringr)
df$year = str_replace(df$year, "X", "")
df$YYMMDD <- paste0(df$year, "-", df$MMDD)

# tell R YYMMDD is a date
df$YYMMDD = as.Date(df$YYMMDD) # also conveniently rids of non leap year Feb 29's

# drop unnecessary columns
to_drop <- c("MMDD", "year")
df <- subset(df, select=!(names(df) %in% to_drop))

# order data by date
df <- df[order(df$YYMMDD),]

head(df)
``` 
We then deal with NA values.

```{r}
# drop initial and ending NAs because we don't have data collected for these dates
library(zoo)
df <- na.trim(df)
```

There seems to be a change point at 1988-01-13 where a new method of measurement may of been put in to place.
Before this date, there is a long stretch of NA values, and all measurements previously were recorded every second day.

```{r}
# There is a period between 1987-12-03 and 1988-01-12 with a stretch of NAs. The following allows this period to be examined.
df_subset <- subset(df, YYMMDD>as.Date("1987-12-01") & YYMMDD<as.Date("1988-01-15"))
print(df_subset)
```

To deal with this long stretch of NAs and the NA values caused by measurement every second day, we propose two options.
Either, we impute the missing data using cubic splines, or drop all observations before the possible changepoint.

```{r}
# impute missing values using cubic splines as one option
df_imputed <- df
df_imputed$extent <- na.spline(df_imputed$extent)

# drop all data before 1988-01-13 as another option
df <- subset(df, YYMMDD>=as.Date("1988-01-13"))
```

We are interested in overall trend, not day to day fluctuations, so we consider aggregating values by month.

```{r}
library(dplyr)
library(lubridate)
df_aggregated <- df %>% 
  group_by(year=year(YYMMDD), month=month(YYMMDD)) %>%
  mutate(avg_extent = mean(extent)) %>%
  distinct(year, month, .keep_all=TRUE) %>%
  subset(select=c(year, month, avg_extent))
```

Now that our data is cleaned and processed, we may proceed with analysis.

\newpage

# Unaggregated Data

We first analyze the unaggregated data.

```{r}
# make a TS object
ExtentTS <- ts(df$extent, frequency=365, start=year(df$YYMMDD[1]))
```

```{r}
plot(ExtentTS)
acf(ExtentTS, lag.max=365)
```

## Variance

From the plot, we see a clear seasonal pattern, and perhaps a decreasing linear trend.

It is unclear whether variance is constant. We test this using the Fligner-Keileen test.

```{r}
# do Fligner test for constant variance.
segments = factor(c(rep(1:4, each=2542), rep(5, times=2543)))
fligner.test(ExtentTS, segments)

segments = factor(c(rep(1:9, each=1271), rep(10, times=1272)))
fligner.test(ExtentTS, segments)

segments = factor(c(rep(1:49, each=254), rep(50, times=265)))
fligner.test(ExtentTS, segments)

segments = factor(c(rep(1:99, each=127), rep(100, times=138)))
fligner.test(ExtentTS, segments)

segments = factor(c(rep(1:34, each=364), rep(35, times=335))) # corresponds more closely to each "wave"
fligner.test(ExtentTS, segments)
```

All give really low p-value so may conclude that variance is not constant. However, this could be due to the amount of data we have.

## Regression

Try to remove non-stationarity using Regression (Multiple Linear, Ridge, Lasso, Elastic Net).

### Multiple Linear Regression

```{r}
mlr <- lm(ExtentTS~time(ExtentTS)+factor(cycle(ExtentTS)))
#summary(mlr) #verrrryyyyy long output and complicated model.
```

```{r}
plot(ExtentTS)
points(time(ExtentTS),predict.lm(mlr),type='l',col='red')
```

We see from the regression, that including daily data leads to a very complicated regression model, and acf plot which has to go way beyond recommended lag to observe an entire period.
For this reason, and because we care mostly about overall trend and not daily fluctuation, we proceed with the aggregated data.

\newpage

# Aggregated Data

We proceed with analyzing the monthly aggregated data.

```{r}
# make a ts object
Avg_ExtentTS <- ts(df_aggregated$avg_extent, frequency=12, start=year(df$YYMMDD[1]))
plot(Avg_ExtentTS)
```

```{r}
plot(decompose(Avg_ExtentTS)$trend)
plot(decompose(Avg_ExtentTS)$season)
plot(decompose(Avg_ExtentTS)$random)
```
From the decomposition, we see there is a significant seasonal pattern, and likely significant trend.

## Variance

From the plot, we see a clear seasonal pattern, and perhaps a decreasing linear trend.

It is unclear whether variance is constant. We test this using the Fligner-Killeen test.

```{r}
# do Fligner test for constant variance.
segments = factor(c(rep(1:4, each=84), rep(5, times=82)))
fligner.test(Avg_ExtentTS, segments)

segments = factor(c(rep(1:9, each=42), rep(10, times=40)))
fligner.test(Avg_ExtentTS, segments)

segments = factor(c(rep(1:19, each=21), rep(20, times=19)))
fligner.test(Avg_ExtentTS, segments)

segments = factor(c(rep(1:34, each=12), rep(35, times=10))) # corresponds to number of years of data
fligner.test(Avg_ExtentTS, segments)
```

All give high p-value so may conclude that variance is relatively constant. This is against expectation, but perhaps this is because the change in variance is not significant over such a small time frame.

```{r}
# define mse function for future use
mse <- function(y, yhat) {
  return(mean((as.vector(y)-as.vector(yhat))^2))
}
```

First, split the data, in to train and test set.

```{r}
Avg_ExtentTS_Train <- window(Avg_ExtentTS, 1988, 2020+11/12)
Avg_ExtentTS_Test <- window(Avg_ExtentTS, 2021, 2022+9/12)
```

## Regression

Try to remove non-stationarity using Regression (Multiple Linear, Ridge, Lasso, Elastic Net).

### Multiple Linear Regression

```{r}
tim <- as.vector(time(Avg_ExtentTS_Train))
season <- factor(cycle(Avg_ExtentTS_Train))

# degree 1 polynomial of time
mlr_train <- lm(Avg_ExtentTS_Train~tim+season)

new <- data.frame(tim=as.vector(time(Avg_ExtentTS_Test)), season=factor(cycle(Avg_ExtentTS_Test)))
mse(Avg_ExtentTS_Test, predict.lm(mlr_train, new))

# degree 2 polynomial of time
mlr_train_2 <- lm(Avg_ExtentTS_Train~poly(tim,2)+season)

mse(Avg_ExtentTS_Test, predict.lm(mlr_train_2, new))

# degree 3 polynomial of time
mlr_train_3 <- lm(Avg_ExtentTS_Train~poly(tim,3)+season)

mse(Avg_ExtentTS_Test, predict.lm(mlr_train_3, new))

#TODO residual diagnostics if proceed with this model
```

The cubic model performs best on the hold out set.

```{r}
tim <- as.vector(time(Avg_ExtentTS))
season <- factor(cycle(Avg_ExtentTS))
mlr <- lm(Avg_ExtentTS~poly(tim, 3)+season)

plot(Avg_ExtentTS)
points(time(Avg_ExtentTS), predict.lm(mlr), type='l', col='red')
plot(mlr$residuals, type="l")
acf(mlr$residuals)
```

### Ridge

```{r}
library(glmnet)

# fit to training data
tim <- as.vector(time(Avg_ExtentTS_Train))
season <- factor(cycle(Avg_ExtentTS_Train))
X <- model.matrix(as.vector(Avg_ExtentTS_Train)~tim+season)
X_2 <- model.matrix(as.vector(Avg_ExtentTS_Train)~poly(tim,2)+season)
X_3 <- model.matrix(as.vector(Avg_ExtentTS_Train)~poly(tim,3)+season)
ridge_train <- glmnet(X, as.vector(Avg_ExtentTS_Train), alpha=0)
ridge_train_2 <- glmnet(X_2, as.vector(Avg_ExtentTS_Train), alpha=0)
ridge_train_3 <- glmnet(X_3, as.vector(Avg_ExtentTS_Train), alpha=0)

# compute mse on training data for each value of lambda
ridge_train_fitted <- predict(ridge_train, X)
ridge_train_fitted_2 <- predict(ridge_train_2, X_2)
ridge_train_fitted_3 <- predict(ridge_train_3, X_3)

mses <- c()
mses_2 <- c()
mses_3 <- c()
for(i in 1:100) {
  mses <- c(mses, mse(Avg_ExtentTS_Train, ridge_train_fitted[,i]))
  mses_2 <- c(mses_2, mse(Avg_ExtentTS_Test, ridge_train_fitted_2[,i]))
  mses_3 <- c(mses_3, mse(Avg_ExtentTS_Test, ridge_train_fitted_3[,i]))
}

min10_mses <- head(sort(mses), 10)
min10_mses_2 <- head(sort(mses_2), 10)
min10_mses_3 <- head(sort(mses_3), 10)

ridge_train_lambdas <- c()
ridge_train_lambdas_2 <- c()
ridge_train_lambdas_3 <- c()

for(m in min10_mses) {
  ridge_train_lambdas <- c(ridge_train_lambdas, ridge_train$lambda[which(mses==m)])
}
for(m in min10_mses_2) {
  ridge_train_lambdas_2 <- c(ridge_train_lambdas_2, ridge_train_2$lambda[which(mses_2==m)])
}
for(m in min10_mses_3) {
  ridge_train_lambdas_3 <- c(ridge_train_lambdas_3, ridge_train_3$lambda[which(mses_3==m)])
}
```

```{r}
# retrain using lambdas that gave the 10 best fits
ridge_train <- glmnet(X, as.vector(Avg_ExtentTS_Train), alpha=0, lambda=ridge_train_lambdas)
ridge_train_2 <- glmnet(X_2, as.vector(Avg_ExtentTS_Train), alpha=0, lambda=ridge_train_lambdas_2)
ridge_train_3 <- glmnet(X_3, as.vector(Avg_ExtentTS_Train), alpha=0, lambda=ridge_train_lambdas_3)

# predict the test set
tim <- as.vector(time(Avg_ExtentTS_Test))
season <- factor(cycle(Avg_ExtentTS_Test))
X <- model.matrix(as.vector(Avg_ExtentTS_Test)~tim+season)
X_2 <- model.matrix(as.vector(Avg_ExtentTS_Test)~poly(tim,2)+season)
X_3 <- model.matrix(as.vector(Avg_ExtentTS_Test)~poly(tim,3)+season)
ridge_predictions <- predict(ridge_train, X)
ridge_predictions_2 <- predict(ridge_train_2, X_2)
ridge_predictions_3 <- predict(ridge_train_3, X_3)

# compute pmse on test set
pmses <- c()
pmses_2 <- c()
pmses_3 <- c()
for(i in 1:10) {
  pmses <- c(pmses, mse(Avg_ExtentTS_Test, ridge_predictions[,i]))
  pmses_2 <- c(pmses_2, mse(Avg_ExtentTS_Test, ridge_predictions_2[,i]))
  pmses_3 <- c(pmses_3, mse(Avg_ExtentTS_Test, ridge_predictions_3[,i]))
}

ridge_train$lambda[which.min(pmses)]
pmses[which.min(pmses)]
ridge_train_2$lambda[which.min(pmses_2)]
pmses_2[which.min(pmses_2)]
ridge_train_3$lambda[which.min(pmses_3)]
pmses_3[which.min(pmses_3)]
```

We see that the degree 1 polynomial gives the lowest MSE.

```{r}
#degree 1 polynomial
tim <- as.vector(time(Avg_ExtentTS))
season <- factor(cycle(Avg_ExtentTS))
X <- model.matrix(as.vector(Avg_ExtentTS)~tim+season)
ridge <- glmnet(X, as.vector(Avg_ExtentTS), alpha=0, lambda=0.1653056)
ridge_fitted <- predict(ridge, X, type="response")
ridge_residuals <- Avg_ExtentTS - ridge_fitted
plot(ridge_residuals, type="l")
plot(Avg_ExtentTS)
points(time(Avg_ExtentTS), ridge_fitted, type='l', col='red')
acf(ridge_residuals)

# TODO this plot but with train test split and acf of train
```

### Lasso

```{r}
library(glmnet)

# fit to training data
tim <- as.vector(time(Avg_ExtentTS_Train))
season <- factor(cycle(Avg_ExtentTS_Train))
X <- model.matrix(as.vector(Avg_ExtentTS_Train)~tim+season)
X_2 <- model.matrix(as.vector(Avg_ExtentTS_Train)~poly(tim,2)+season)
X_3 <- model.matrix(as.vector(Avg_ExtentTS_Train)~poly(tim,3)+season)
lasso_train <- glmnet(X, as.vector(Avg_ExtentTS_Train), alpha=1)
lasso_train_2 <- glmnet(X_2, as.vector(Avg_ExtentTS_Train), alpha=1)
lasso_train_3 <- glmnet(X_3, as.vector(Avg_ExtentTS_Train), alpha=1)

# compute mse on training data for each value of lambda
lasso_train_fitted <- predict(lasso_train, X)
lasso_train_fitted_2 <- predict(lasso_train_2, X_2)
lasso_train_fitted_3 <- predict(lasso_train_3, X_3)

mses <- c()
mses_2 <- c()
mses_3 <- c()
for(i in 1:67) {
  mses <- c(mses, mse(Avg_ExtentTS_Train, lasso_train_fitted[,i]))
}
for(i in 1:68) {
  mses_2 <- c(mses_2, mse(Avg_ExtentTS_Test, lasso_train_fitted_2[,i]))
  mses_3 <- c(mses_3, mse(Avg_ExtentTS_Test, lasso_train_fitted_3[,i]))
}

min10_mses <- head(sort(mses), 10)
min10_mses_2 <- head(sort(mses_2), 10)
min10_mses_3 <- head(sort(mses_3), 10)

lasso_train_lambdas <- c()
lasso_train_lambdas_2 <- c()
lasso_train_lambdas_3 <- c()

for(m in min10_mses) {
  lasso_train_lambdas <- c(lasso_train_lambdas, lasso_train$lambda[which(mses==m)])
}
for(m in min10_mses_2) {
  lasso_train_lambdas_2 <- c(lasso_train_lambdas_2, lasso_train_2$lambda[which(mses_2==m)])
}
for(m in min10_mses_3) {
  lasso_train_lambdas_3 <- c(lasso_train_lambdas_3, lasso_train_3$lambda[which(mses_3==m)])
}
```

```{r}
# retrain using lambdas that gave the 10 best fits
lasso_train <- glmnet(X, as.vector(Avg_ExtentTS_Train), alpha=0, lambda=lasso_train_lambdas)
lasso_train_2 <- glmnet(X_2, as.vector(Avg_ExtentTS_Train), alpha=0, lambda=lasso_train_lambdas_2)
lasso_train_3 <- glmnet(X_3, as.vector(Avg_ExtentTS_Train), alpha=0, lambda=lasso_train_lambdas_3)

# predict the test set
tim <- as.vector(time(Avg_ExtentTS_Test))
season <- factor(cycle(Avg_ExtentTS_Test))
X <- model.matrix(as.vector(Avg_ExtentTS_Test)~tim+season)
X_2 <- model.matrix(as.vector(Avg_ExtentTS_Test)~poly(tim,2)+season)
X_3 <- model.matrix(as.vector(Avg_ExtentTS_Test)~poly(tim,3)+season)
lasso_predictions <- predict(lasso_train, X)
lasso_predictions_2 <- predict(lasso_train_2, X_2)
lasso_predictions_3 <- predict(lasso_train_3, X_3)

# compute pmse on test set
pmses <- c()
pmses_2 <- c()
pmses_3 <- c()
for(i in 1:10) {
  pmses <- c(pmses, mse(Avg_ExtentTS_Test, lasso_predictions[,i]))
  pmses_2 <- c(pmses_2, mse(Avg_ExtentTS_Test, lasso_predictions_2[,i]))
  pmses_3 <- c(pmses_3, mse(Avg_ExtentTS_Test, lasso_predictions_3[,i]))
}

lasso_train$lambda[which.min(pmses)]
pmses[which.min(pmses)]
lasso_train_2$lambda[which.min(pmses_2)]
pmses_2[which.min(pmses_2)]
lasso_train_3$lambda[which.min(pmses_3)]
pmses_3[which.min(pmses_3)]
```

We see that the degree 1 polynomial gives the lowest MSE.

```{r}
# degree 1 polynomial of time
tim <- as.vector(time(Avg_ExtentTS))
season <- factor(cycle(Avg_ExtentTS))
X <- model.matrix(as.vector(Avg_ExtentTS)~tim+season)
lasso <- glmnet(X, as.vector(Avg_ExtentTS), alpha=1, lambda=0.003561401)
lasso_fitted <- predict(lasso, X, type="response")
lasso_residuals <- Avg_ExtentTS - lasso_fitted
plot(lasso_residuals, type="l")
plot(Avg_ExtentTS)
points(time(Avg_ExtentTS), lasso_fitted, type='l', col='red')
acf(lasso_residuals)

# TODO this plot but with train test split and acf of train
```

### Elastic Net 

```{r}
library(glmnet)
alpha_seq <- seq(0.1, 0.9, by=0.1)

en_train_min_lamdas <- c()
en_train_min_lamdas_2 <- c()
en_train_min_lamdas_3 <- c()
min_pmses <- c()
min_pmses_2 <- c()
min_pmses_3 <- c()

for(a in alpha_seq){
  # fit to training data
  tim <- as.vector(time(Avg_ExtentTS_Train))
  season <- factor(cycle(Avg_ExtentTS_Train))
  X <- model.matrix(as.vector(Avg_ExtentTS_Train)~tim+season)
  X_2 <- model.matrix(as.vector(Avg_ExtentTS_Train)~poly(tim,2)+season)
  X_3 <- model.matrix(as.vector(Avg_ExtentTS_Train)~poly(tim,3)+season)
  en_train <- glmnet(X, as.vector(Avg_ExtentTS_Train), alpha=a)
  en_train_2 <- glmnet(X_2, as.vector(Avg_ExtentTS_Train), alpha=a)
  en_train_3 <- glmnet(X_3, as.vector(Avg_ExtentTS_Train), alpha=a)
  
  # compute mse on training data for each value of lambda
  en_train_fitted <- predict(en_train, X)
  en_train_fitted_2 <- predict(en_train_2, X_2)
  en_train_fitted_3 <- predict(en_train_3, X_3)
  
  mses <- c()
  mses_2 <- c()
  mses_3 <- c()
  for(i in 1:length(en_train$lambda)) {
    mses <- c(mses, mse(Avg_ExtentTS_Train, en_train_fitted[,i]))
  }
  for(i in 1:length(en_train_2$lambda)) {
    mses_2 <- c(mses_2, mse(Avg_ExtentTS_Test, en_train_fitted_2[,i]))
  }
  for(i in 1:length(en_train_3$lambda)) {
    mses_3 <- c(mses_3, mse(Avg_ExtentTS_Test, en_train_fitted_3[,i]))
  }
  
  min10_mses <- head(sort(mses), 10)
  min10_mses_2 <- head(sort(mses_2), 10)
  min10_mses_3 <- head(sort(mses_3), 10)
  
  en_train_lambdas <- c()
  en_train_lambdas_2 <- c()
  en_train_lambdas_3 <- c()
  
  for(m in min10_mses) {
    en_train_lambdas <- c(en_train_lambdas, en_train$lambda[which(mses==m)])
  }
  for(m in min10_mses_2) {
    en_train_lambdas_2 <- c(en_train_lambdas_2, en_train_2$lambda[which(mses_2==m)])
  }
  for(m in min10_mses_3) {
    en_train_lambdas_3 <- c(en_train_lambdas_3, en_train_3$lambda[which(mses_3==m)])
  }
  
  
  # retrain using lambdas that gave the 10 best fits
  en_train <- glmnet(X, as.vector(Avg_ExtentTS_Train), alpha=a, lambda=en_train_lambdas)
  en_train_2 <- glmnet(X_2, as.vector(Avg_ExtentTS_Train), alpha=a, lambda=en_train_lambdas_2)
  en_train_3 <- glmnet(X_3, as.vector(Avg_ExtentTS_Train), alpha=a, lambda=en_train_lambdas_3)
  
  # predict the test set
  tim <- as.vector(time(Avg_ExtentTS_Test))
  season <- factor(cycle(Avg_ExtentTS_Test))
  X <- model.matrix(as.vector(Avg_ExtentTS_Test)~tim+season)
  X_2 <- model.matrix(as.vector(Avg_ExtentTS_Test)~poly(tim,2)+season)
  X_3 <- model.matrix(as.vector(Avg_ExtentTS_Test)~poly(tim,3)+season)
  en_predictions <- predict(en_train, X)
  en_predictions_2 <- predict(en_train_2, X_2)
  en_predictions_3 <- predict(en_train_3, X_3)
  
  # compute pmse on test set
  pmses <- c()
  pmses_2 <- c()
  pmses_3 <- c()
  for(i in 1:10) {
    pmses <- c(pmses, mse(Avg_ExtentTS_Test, en_predictions[,i]))
    pmses_2 <- c(pmses_2, mse(Avg_ExtentTS_Test, en_predictions_2[,i]))
    pmses_3 <- c(pmses_3, mse(Avg_ExtentTS_Test, en_predictions_3[,i]))
  }
  
  min_pmses <- c(min_pmses, pmses[which.min(pmses)])
  min_pmses_2 <- c(min_pmses_2, pmses_2[which.min(pmses_2)])
  min_pmses_3 <- c(min_pmses_3, pmses_3[which.min(pmses_3)])

  en_train_min_lamdas <- c(en_train_min_lamdas, en_train$lambda[which.min(pmses)])
  en_train_min_lamdas_2 <- c(en_train_min_lamdas_2, en_train_2$lambda[which.min(pmses_2)])
  en_train_min_lamdas_3 <- c(en_train_min_lamdas_3, en_train_3$lambda[which.min(pmses_3)])
}

min_pmses[which.min(min_pmses)]
alpha_seq[which.min(min_pmses)]
en_train_min_lamdas[which.min(min_pmses)]

min_pmses_2[which.min(min_pmses_2)]
alpha_seq[which.min(min_pmses_2)]
en_train_min_lamdas_2[which.min(min_pmses_2)]

min_pmses_3[which.min(min_pmses_3)]
alpha_seq[which.min(min_pmses_3)]
en_train_min_lamdas_3[which.min(min_pmses_3)]
```

We see that the degree 1 polynomial gives the lowest MSE.

```{r}
#degree 1 polynomial
tim <- as.vector(time(Avg_ExtentTS))
season <- factor(cycle(Avg_ExtentTS))
X <- model.matrix(as.vector(Avg_ExtentTS)~tim+season)
ridge <- glmnet(X, as.vector(Avg_ExtentTS), alpha=0.9, lambda=0.004342926)
ridge_fitted <- predict(ridge, X, type="response")
ridge_residuals <- Avg_ExtentTS - ridge_fitted
plot(ridge_residuals, type="l")
plot(Avg_ExtentTS)
points(time(Avg_ExtentTS), ridge_fitted, type='l', col='red')
acf(ridge_residuals)

# TODO this plot but with train test split and acf of train
```

## Holt-Winters

Try to remove non-stationarity using exponential smoothing, double exponential smoothing, additive HW, and multiplicative HW.

### Exponential Smoothing

```{r}
es <- HoltWinters(Avg_ExtentTS_Train, gamma = FALSE , beta = FALSE)
predict_es = predict(es, n.ahead=22)
mse(Avg_ExtentTS_Test, predict_es)
```

### Double Exponential Smoothing

```{r}
des <- HoltWinters(Avg_ExtentTS_Train, gamma = FALSE)
predict_des = predict(des, n.ahead=22)
mse(Avg_ExtentTS_Test, predict_des)
```

### No Trend

```{r}
no_trend <- HoltWinters(Avg_ExtentTS_Train, beta = FALSE)
predict_no_trend = predict(no_trend, n.ahead=22)
mse(Avg_ExtentTS_Test, predict_no_trend)
```

### Additive Holt-Winters

```{r}
additive <- HoltWinters(Avg_ExtentTS_Train, seasonal = "additive")
predict_additive = predict(additive, n.ahead=22)
mse(Avg_ExtentTS_Test, predict_additive)
```

### Multiplicative Holt-Winters

```{r}
multiplicative <- HoltWinters(Avg_ExtentTS_Train, seasonal = "multiplicative")
predict_multiplicative = predict(multiplicative, n.ahead=22)
mse(Avg_ExtentTS_Test, predict_additive)
```

Best of HW models seems to be additive/multiplicatice model. We fit this model to the entire data.

```{r}
hw_additive <- HoltWinters(Avg_ExtentTS, seasonal = "additive")
residuals_HW <- as.vector(Avg_ExtentTS[which(time(Avg_ExtentTS)>=1989)]) - hw_additive$fitted[,1]
plot(residuals_HW, type="l")
acf(residuals_HW, lag.max=36)
plot(Avg_ExtentTS)
points(time(Avg_ExtentTS)[which(time(Avg_ExtentTS)>=1989)], hw_additive$fitted[,1], type='l', col='red')
#plot(hw_additive)
```
```{r}
# Same as above but on training data
hw_additive_train <- HoltWinters(Avg_ExtentTS_Train, seasonal = "additive")
residuals_HW_train <- as.vector(Avg_ExtentTS_Train[which(time(Avg_ExtentTS_Train)>=1989)]) - hw_additive_train$fitted[,1]
plot(residuals_HW_train, type="l")
acf(residuals_HW_train, lag.max=36)
plot(Avg_ExtentTS_Train)
points(time(Avg_ExtentTS_Train)[which(time(Avg_ExtentTS_Train)>=1989)], hw_additive_train$fitted[,1], type='l', col='red')
#plot(hw_additive)
```

```{r}
# no_trend on training data
residuals_no_trend_train <- as.vector(Avg_ExtentTS_Train[which(time(Avg_ExtentTS_Train)>=1989)]) - no_trend$fitted[,1]
plot(residuals_no_trend_train, type="l")
acf(residuals_no_trend_train, lag.max=36)
plot(Avg_ExtentTS_Train)
points(time(Avg_ExtentTS_Train)[which(time(Avg_ExtentTS_Train)>=1989)], no_trend$fitted[,1], type='l', col='red')
#plot(hw_additive)
```
```{r}
#TODO COULD fit SARMA models on HW residuals but probably overkill
acf(residuals_no_trend_train, lag.max=36)
pacf(residuals_no_trend_train, lag.max=36)
```

## Differencing on Entire Data

Try differencing to remove non-stationarity.

```{r}
acf(Avg_ExtentTS, lag.max=36)
plot(Avg_ExtentTS)
```

```{r}
#differencing in lag of season
diff12.Extent=diff(Avg_ExtentTS, lag=12)
acf(diff12.Extent, lag.max=36)
pacf(diff12.Extent, lag.max=36)
plot(diff12.Extent)
```

```{r}
#regular differencing
diff.Extent=diff(Avg_ExtentTS)
acf(diff.Extent, lag.max=36)
plot(diff.Extent)
```

```{r}
#seasonal+regular differencing
diff12.diff.Extent=diff(diff12.Extent)
acf(diff12.diff.Extent, lag.max=36)
plot(diff12.diff.Extent)
```

It seems that regression performs poorly in terms of removing non-stationarity compared to HW and Differencing. HW and differencing seem to perform similarly. For simplicity, we proceed with differencing.

```{r}
acf(diff12.diff.Extent, lag.max=36)
pacf(diff12.diff.Extent, lag.max=36)
```
## Differencing on Train Data

Try differencing to remove non-stationarity.

```{r}
acf(Avg_ExtentTS_Train, lag.max=36)
plot(Avg_ExtentTS_Train)
```

```{r}
#differencing in lag of season
diff12.Extent=diff(Avg_ExtentTS_Train, lag=12)
acf(diff12.Extent, lag.max=50)
pacf(diff12.Extent, lag.max=50)
plot(diff12.Extent)
```

```{r}
#regular differencing
diff.Extent=diff(Avg_ExtentTS_Train)
acf(diff.Extent, lag.max=36)
plot(diff.Extent)
```

```{r}
# seasonal+regular differencing
diff12.diff.Extent=diff(diff12.Extent)
acf(diff12.diff.Extent, lag.max=36)
plot(diff12.diff.Extent)
```

It seems that regression performs poorly in terms of removing non-stationarity compared to HW and Differencing. HW and differencing seem to perform similarly. For simplicity, we proceed with differencing. #TODO reword this

```{r}
acf(diff12.diff.Extent, lag.max=50)
pacf(diff12.diff.Extent, lag.max=50)
```
We propose the following models:
#TODO


## Smoothing, followed by differencing

Try smoothing before differencing to see effect on acf

```{r}
smoothing <- HoltWinters(Avg_ExtentTS_Train, season="additive")
smoothed <- smoothing$fitted[,1]
diff12.Extent_smooth=diff(smoothed, lag=12)
acf(diff12.Extent_smooth, lag.max=36)
plot(diff12.Extent_smooth)
diff12.diff.Extent_smooth=diff(diff12.Extent_smooth)
acf(diff12.diff.Extent_smooth, lag.max=36)
plot(diff12.diff.Extent_smooth)
```
```{r}
acf(diff12.diff.Extent_smooth, lag.max=36)
pacf(diff12.diff.Extent_smooth, lag.max=36)
```

# Model Fitting

```{r}
library(astsa)

#SARIMA(0,1,2)x(0,1,1)_12
model_1_train <- sarima(Avg_ExtentTS_Train, p=0, d=1, q=2, P=0, D=1, Q=1, S=12 , details = TRUE)
model_1_train_residuals = resid(model_1_train$fit)
hist(model_1_train_residuals)
shapiro.test(model_1_train_residuals)
```

```{r}
#SARIMA(0,1,2)x(3,1,0)_12
model_2_train <- sarima(Avg_ExtentTS_Train, p=0, d=1, q=2, P=3, D=1, Q=0, S=12 , details = TRUE)
model_2_train_residuals = resid(model_2_train$fit)
hist(model_2_train_residuals)
shapiro.test(model_2_train_residuals)
```

```{r}
#SARIMA(0,1,2)x(1,1,1)_12
model_3_train <- sarima(Avg_ExtentTS_Train, p=0, d=1, q=2, P=1, D=1, Q=1, S=12 , details = TRUE)
model_3_train_residuals = resid(model_3_train$fit)
hist(model_3_train_residuals)
shapiro.test(model_3_train_residuals)
```
```{r}
#SARIMA(4,1,0)x(0,1,1)_12
model_4_train <- sarima(Avg_ExtentTS_Train, p=4, d=1, q=0, P=0, D=1, Q=1, S=12 , details = TRUE)
model_4_train_residuals = resid(model_4_train$fit)
hist(model_4_train_residuals)
shapiro.test(model_4_train_residuals)
```

```{r}
#SARIMA(4,1,0)x(3,1,0)_12
model_5_train <- sarima(Avg_ExtentTS_Train, p=4, d=1, q=0, P=3, D=1, Q=0, S=12 , details = TRUE)
model_5_train_residuals = resid(model_5_train$fit)
hist(model_5_train_residuals)
shapiro.test(model_5_train_residuals)
```

```{r}
#SARIMA(4,1,0)x(1,1,1)_12
model_6_train <- sarima(Avg_ExtentTS_Train, p=4, d=1, q=0, P=1, D=1, Q=1, S=12 , details = TRUE)
model_6_train_residuals = resid(model_6_train$fit)
hist(model_6_train_residuals)
shapiro.test(model_6_train_residuals)
```
```{r}
#SARIMA(5,1,0)x(0,1,1)_12
model_7_train <- sarima(Avg_ExtentTS_Train, p=5, d=1, q=0, P=0, D=1, Q=1, S=12 , details = TRUE)
model_7_train_residuals = resid(model_7_train$fit)
hist(model_7_train_residuals)
shapiro.test(model_7_train_residuals)
```

```{r}
#SARIMA(5,1,0)x(3,1,0)_12
model_8_train <- sarima(Avg_ExtentTS_Train, p=5, d=1, q=0, P=3, D=1, Q=0, S=12 , details = TRUE)
model_8_train_residuals = resid(model_8_train$fit)
hist(model_8_train_residuals)
shapiro.test(model_8_train_residuals)
```

```{r}
#SARIMA(5,1,0)x(1,1,1)_12
model_9_train <- sarima(Avg_ExtentTS_Train, p=5, d=1, q=0, P=1, D=1, Q=1, S=12 , details = TRUE)
model_9_train_residuals = resid(model_9_train$fit)
hist(model_9_train_residuals)
shapiro.test(model_9_train_residuals)
```

```{r}
#SARIMA(1,1,1)x(0,1,1)_12
model_10_train <- sarima(Avg_ExtentTS_Train, p=1, d=1, q=1, P=0, D=1, Q=1, S=12 , details = TRUE)
model_10_train_residuals = resid(model_10_train$fit)
hist(model_10_train_residuals)
shapiro.test(model_10_train_residuals)
```

```{r}
#SARIMA(1,1,1)x(3,1,0)_12
model_11_train <- sarima(Avg_ExtentTS_Train, p=1, d=1, q=1, P=3, D=1, Q=0, S=12 , details = TRUE)
model_11_train_residuals = resid(model_11_train$fit)
hist(model_11_train_residuals)
shapiro.test(model_11_train_residuals)
```

```{r}
#SARIMA(1,1,1)x(1,1,1)_12
model_12_train <- sarima(Avg_ExtentTS_Train, p=1, d=1, q=1, P=1, D=1, Q=1, S=12 , details = TRUE)
model_12_train_residuals = resid(model_4_train$fit)
hist(model_12_train_residuals)
shapiro.test(model_12_train_residuals)
```
```{r}
#SARIMA(1,1,2)x(3,1,0)_12
model_13_train <- sarima(Avg_ExtentTS_Train, p=1, d=1, q=2, P=3, D=1, Q=0, S=12 , details = TRUE)
model_13_train_residuals = resid(model_13_train$fit)
hist(model_13_train_residuals)
shapiro.test(model_13_train_residuals)
```

```{r}
#SARIMA(2,1,1)x(3,1,0)_12
model_14_train <- sarima(Avg_ExtentTS_Train, p=2, d=1, q=1, P=3, D=1, Q=0, S=12 , details = TRUE)
model_14_train_residuals = resid(model_14_train$fit)
hist(model_14_train_residuals)
shapiro.test(model_14_train_residuals)
```

```{r}
#SARIMA(2,1,2)x(3,1,0)_12
model_15_train <- sarima(Avg_ExtentTS_Train, p=2, d=1, q=2, P=3, D=1, Q=0, S=12 , details = TRUE)
model_15_train_residuals = resid(model_15_train$fit)
hist(model_15_train_residuals)
shapiro.test(model_15_train_residuals)
```
```{r}
#SARIMA(1,1,3)x(3,1,0)_12
model_16_train <- sarima(Avg_ExtentTS_Train, p=1, d=1, q=3, P=3, D=1, Q=0, S=12 , details = TRUE)
model_16_train_residuals = resid(model_16_train$fit)
hist(model_16_train_residuals)
shapiro.test(model_16_train_residuals)
```

```{r}
#SARIMA(3,1,1)x(3,1,0)_12
#model_17_train <- sarima(Avg_ExtentTS_Train, p=3, d=1, q=1, P=3, D=1, Q=0, S=12, details = TRUE)
#model_17_train_residuals = resid(model_17_train$fit)
#hist(model_17_train_residuals)
#shapiro.test(model_17_train_residuals)
#gives an error when run
```

```{r}
#SARIMA(2,1,3)x(3,1,0)_12
model_18_train <- sarima(Avg_ExtentTS_Train, p=2, d=1, q=3, P=3, D=1, Q=0, S=12 , details = TRUE)
model_18_train_residuals = resid(model_18_train$fit)
hist(model_18_train_residuals)
shapiro.test(model_18_train_residuals)
```

```{r}
#SARIMA(3,1,2)x(3,1,0)_12
model_19_train <- sarima(Avg_ExtentTS_Train, p=3, d=1, q=2, P=3, D=1, Q=0, S=12 , details = TRUE)
model_19_train_residuals = resid(model_19_train$fit)
hist(model_19_train_residuals)
shapiro.test(model_19_train_residuals)
```

```{r}
#SARIMA(3,1,3)x(3,1,0)_12
model_20_train <- sarima(Avg_ExtentTS_Train, p=3, d=1, q=3, P=3, D=1, Q=0, S=12 , details = TRUE)
model_20_train_residuals = resid(model_20_train$fit)
hist(model_20_train_residuals)
shapiro.test(model_20_train_residuals)
```

```{r}
library(huxtable)
goodness_of_fit <- hux(
        Model = c('SARIMA(0,1,2)x(0,1,1)_12', 'SARIMA(0,1,2)x(3,1,0)_12', 'SARIMA(0,1,2)x(1,1,1)_12', 
                  'SARIMA(4,1,0)x(0,1,1)_12', 'SARIMA(4,1,0)x(3,1,0)_12', 'SARIMA(4,1,0)x(1,1,1)_12',
                  'SARIMA(5,1,0)x(0,1,1)_12', 'SARIMA(5,1,0)x(3,1,0)_12', 'SARIMA(5,1,0)x(1,1,1)_12',
                  'SARIMA(1,1,1)x(0,1,1)_12', 'SARIMA(1,1,1)x(3,1,0)_12', 'SARIMA(1,1,1)x(1,1,1)_12',
                  'SARIMA(1,1,2)x(3,1,0)_12', 'SARIMA(2,1,1)x(3,1,0)_12', 'SARIMA(2,1,2)x(3,1,0)_12',
                  'SARIMA(1,1,3)x(3,1,0)_12', 'SARIMA(2,1,3)x(3,1,0)_12', 'SARIMA(3,1,2)x(3,1,0)_12',
                  'SARIMA(1,1,3)x(3,1,0)_12'),
        AIC = c(model_1_train$AIC, model_2_train$AIC, model_3_train$AIC, 
                model_4_train$AIC, model_5_train$AIC, model_6_train$AIC, 
                model_7_train$AIC, model_8_train$AIC, model_9_train$AIC,
                model_10_train$AIC, model_11_train$AIC, model_12_train$AIC,
                model_13_train$AIC, model_14_train$AIC, model_15_train$AIC,
                model_16_train$AIC, model_18_train$AIC, model_19_train$AIC,
                model_20_train$AIC),
        AICc = c(model_1_train$AICc, model_2_train$AICc, model_3_train$AICc, 
                model_4_train$AICc, model_5_train$AICc, model_6_train$AICc, 
                model_7_train$AICc, model_8_train$AICc, model_9_train$AICc,
                model_10_train$AICc, model_11_train$AICc, model_12_train$AICc,
                model_13_train$AICc, model_14_train$AICc, model_15_train$AICc,
                model_16_train$AICc, model_18_train$AICc, model_19_train$AICc,
                model_20_train$AICc),
        BIC = c(model_1_train$BIC, model_2_train$BIC, model_3_train$BIC,
                model_4_train$BIC, model_5_train$BIC, model_6_train$BIC,
                model_7_train$BIC, model_8_train$BIC, model_9_train$BIC,
                model_10_train$BIC, model_11_train$BIC, model_12_train$BIC,
                model_13_train$BIC, model_14_train$BIC, model_15_train$BIC,
                model_16_train$BIC, model_18_train$BIC, model_19_train$BIC,
                model_20_train$BIC),
        MSE = c(mean(model_1_train_residuals^2), mean(model_2_train_residuals^2), mean(model_3_train_residuals^2),
                mean(model_4_train_residuals^2), mean(model_5_train_residuals^2), mean(model_6_train_residuals^2),
                mean(model_7_train_residuals^2), mean(model_8_train_residuals^2), mean(model_9_train_residuals^2),
                mean(model_10_train_residuals^2), mean(model_11_train_residuals^2), mean(model_12_train_residuals^2),
                mean(model_13_train_residuals^2), mean(model_14_train_residuals^2), mean(model_15_train_residuals^2),
                mean(model_16_train_residuals^2), mean(model_18_train_residuals^2), mean(model_19_train_residuals^2),
                mean(model_20_train_residuals^2))
      )

goodness_of_fit %>% 
  set_number_format(col=c(2,3,4,5), value=3) %>%
  set_bottom_border(c(1,13,16), everywhere) %>%
  set_bold(c(12,14,15,16,17,18,19,20), everywhere) %>%
  set_background_color(c(12,14,15,16,17,18,19,20), everywhere, "grey95")
```

\newpage

 .

\newpage

## Model Selection

```{r}
model_8_train_forecast<- sarima.for(Avg_ExtentTS_Train, n.ahead=22, p=1,d=1,q=1,P=3,D=1,Q=0,S=12)
lines(Avg_ExtentTS_Test,col='blue',type='b',pch=16)
model_10_train_forecast<- sarima.for(Avg_ExtentTS_Train, n.ahead=22, p=1,d=1,q=2,P=3,D=1,Q=0,S=12)
lines(Avg_ExtentTS_Test,col='blue',type='b',pch=16)
model_11_train_forecast<- sarima.for(Avg_ExtentTS_Train, n.ahead=22, p=2,d=1,q=1,P=3,D=1,Q=0,S=12)
lines(Avg_ExtentTS_Test,col='blue',type='b',pch=16)
model_12_train_forecast<- sarima.for(Avg_ExtentTS_Train, n.ahead=22, p=2,d=1,q=2,P=3,D=1,Q=0,S=12)
lines(Avg_ExtentTS_Test,col='blue',type='b',pch=16)

mean((model_8_train_forecast$pred-Avg_ExtentTS_Test)^2)
mean((model_10_train_forecast$pred-Avg_ExtentTS_Test)^2)
mean((model_11_train_forecast$pred-Avg_ExtentTS_Test)^2)
mean((model_12_train_forecast$pred-Avg_ExtentTS_Test)^2)
```

#TODO could test more combinations of ARMA models, athough not necessary
#TODO decide on a final model, and make predictions

# Model Fitting on Seasonally differenced data

```{r}
#SARIMA(1,0,1)x(0,1,1)_12
model_21_train <- sarima(Avg_ExtentTS_Train, p=1, d=0, q=1, P=0, D=1, Q=1, S=12 , details = TRUE)
model_21_train_residuals = resid(model_21_train$fit)
hist(model_21_train_residuals)
shapiro.test(model_21_train_residuals)
```

```{r}
#SARIMA(1,0,1)x(1,1,0)_12
model_22_train <- sarima(Avg_ExtentTS_Train, p=1, d=0, q=1, P=1, D=1, Q=0, S=12 , details = TRUE)
model_22_train_residuals = resid(model_22_train$fit)
hist(model_22_train_residuals)
shapiro.test(model_22_train_residuals)
```

```{r}
#SARIMA(1,0,1)x(0,1,3)_12
model_23_train <- sarima(Avg_ExtentTS_Train, p=1, d=0, q=1, P=0, D=1, Q=3, S=12 , details = TRUE)
model_23_train_residuals = resid(model_23_train$fit)
hist(model_23_train_residuals)
shapiro.test(model_23_train_residuals)
```

```{r}
#SARIMA(1,0,1)x(0,1,4)_12
model_24_train <- sarima(Avg_ExtentTS_Train, p=1, d=0, q=1, P=0, D=1, Q=4, S=12 , details = TRUE)
model_24_train_residuals = resid(model_24_train$fit)
hist(model_24_train_residuals)
shapiro.test(model_24_train_residuals)
```

```{r}
#SARIMA(1,0,1)x(1,1,1)_12
model_25_train <- sarima(Avg_ExtentTS_Train, p=1, d=0, q=1, P=1, D=1, Q=1, S=12 , details = TRUE)
model_25_train_residuals = resid(model_25_train$fit)
hist(model_25_train_residuals)
shapiro.test(model_25_train_residuals)
```

```{r}
#SARIMA(13,0,0)x(0,1,1)_12
model_26_train <- sarima(Avg_ExtentTS_Train, p=13, d=0, q=0, P=0, D=1, Q=1, S=12 , details = TRUE)
model_26_train_residuals = resid(model_26_train$fit)
hist(model_26_train_residuals)
shapiro.test(model_26_train_residuals)
```

```{r}
#SARIMA(13,0,0)x(1,1,0)_12
model_27_train <- sarima(Avg_ExtentTS_Train, p=13, d=0, q=0, P=1, D=1, Q=0, S=12 , details = TRUE)
model_27_train_residuals = resid(model_27_train$fit)
hist(model_27_train_residuals)
shapiro.test(model_27_train_residuals)
```

```{r}
#SARIMA(13,0,0)x(0,1,3)_12
model_28_train <- sarima(Avg_ExtentTS_Train, p=13, d=0, q=0, P=0, D=1, Q=3, S=12 , details = TRUE)
model_28_train_residuals = resid(model_28_train$fit)
hist(model_28_train_residuals)
shapiro.test(model_28_train_residuals)
```

```{r}
#SARIMA(13,0,0)x(0,1,4)_12
model_29_train <- sarima(Avg_ExtentTS_Train, p=13, d=0, q=0, P=0, D=1, Q=4, S=12 , details = TRUE)
model_29_train_residuals = resid(model_29_train$fit)
hist(model_29_train_residuals)
shapiro.test(model_29_train_residuals)
```

```{r}
#SARIMA(13,0,0)x(1,1,1)_12
model_30_train <- sarima(Avg_ExtentTS_Train, p=13, d=0, q=0, P=1, D=1, Q=1, S=12 , details = TRUE)
model_30_train_residuals = resid(model_30_train$fit)
hist(model_30_train_residuals)
shapiro.test(model_30_train_residuals)
```

```{r}
#SARIMA(1,0,2)x(0,1,1)_12
model_31_train <- sarima(Avg_ExtentTS_Train, p=1, d=0, q=2, P=0, D=1, Q=1, S=12 , details = TRUE)
model_31_train_residuals = resid(model_31_train$fit)
hist(model_31_train_residuals)
shapiro.test(model_31_train_residuals)
```

```{r}
#SARIMA(2,0,1)x(0,1,1)_12
model_32_train <- sarima(Avg_ExtentTS_Train, p=2, d=0, q=1, P=0, D=1, Q=1, S=12 , details = TRUE)
model_32_train_residuals = resid(model_32_train$fit)
hist(model_32_train_residuals)
shapiro.test(model_32_train_residuals)
```

```{r}
#SARIMA(2,0,2)x(0,1,1)_12
model_33_train <- sarima(Avg_ExtentTS_Train, p=2, d=0, q=2, P=0, D=1, Q=1, S=12 , details = TRUE)
model_33_train_residuals = resid(model_33_train$fit)
hist(model_33_train_residuals)
shapiro.test(model_33_train_residuals)
```
```{r}
# Weird combo of optimal parameters for d=0, and d=1
#SARIMA(1,0,1)x(3,1,0)_12
model_34_train <- sarima(Avg_ExtentTS_Train, p=1, d=0, q=1, P=3, D=1, Q=0, S=12 , details = TRUE)
model_34_train_residuals = resid(model_34_train$fit)
hist(model_34_train_residuals)
shapiro.test(model_34_train_residuals)
```
```{r}
# Weird combo of optimal parameters for d=0, and d=1
#SARIMA(1,0,1)x(3,1,0)_12
model_35_train <- sarima(Avg_ExtentTS_Train, p=1, d=0, q=1, P=4, D=1, Q=0, S=12 , details = TRUE)
model_35_train_residuals = resid(model_34_train$fit)
hist(model_35_train_residuals)
shapiro.test(model_35_train_residuals)
```

#TODO try 'SARIMA(1,0,3)x(0,1,1)_12', 'SARIMA(3,0,1)x(0,1,1)_12', 'SARIMA(2,0,3)x(0,1,1)_12', 'SARIMA(3,0,2)x(0,1,1)_12', 'SARIMA(3,0,3)x(0,1,1)_12'

```{r}
library(huxtable)
goodness_of_fit <- hux(
        Model = c('SARIMA(1,0,1)x(0,1,1)_12', 'SARIMA(1,0,1)x(1,1,0)_12', 'SARIMA(1,0,1)x(0,1,3)_12', 'SARIMA(1,0,1)x(0,1,4)_12', 'SARIMA(1,0,1)x(1,1,1)_12',
                  'SARIMA(13,0,0)x(0,1,1)_12', 'SARIMA(13,0,0)x(1,1,0)_12', 'SARIMA(13,0,0)x(0,1,3)_12', 'SARIMA(13,0,0)x(0,1,4)_12', 'SARIMA(13,0,0)x(1,1,1)_12',
                  'SARIMA(1,0,2)x(0,1,1)_12', 'SARIMA(2,0,1)x(0,1,1)_12', 'SARIMA(2,0,2)x(0,1,1)_12', 'SARIMA(1,0,1)x(3,1,0)_12', 'SARIMA(1,0,1)x(4,1,0)_12'),
        AIC = c(model_21_train$AIC, model_22_train$AIC, model_23_train$AIC, model_24_train$AIC, model_25_train$AIC,
                model_26_train$AIC, model_27_train$AIC, model_28_train$AIC, model_29_train$AIC, model_30_train$AIC,
                model_31_train$AIC, model_32_train$AIC, model_33_train$AIC, model_34_train$AIC, model_35_train$AIC),
        AICc = c(model_21_train$AICc, model_22_train$AICc, model_23_train$AICc, model_24_train$AICc, model_25_train$AICc, 
                model_26_train$AICc, model_27_train$AICc, model_28_train$AICc, model_29_train$AICc, model_30_train$AICc,
                model_31_train$AICc, model_32_train$AICc, model_33_train$AICc, model_34_train$AICc, model_35_train$AICc),
        BIC = c(model_21_train$BIC, model_22_train$BIC, model_23_train$BIC, model_24_train$BIC, model_25_train$BIC,
                model_26_train$BIC, model_27_train$BIC, model_28_train$BIC, model_29_train$BIC, model_30_train$BIC,
                model_31_train$BIC, model_32_train$BIC, model_33_train$BIC, model_34_train$BIC, model_35_train$BIC),
        MSE = c(mean(model_21_train_residuals^2), mean(model_22_train_residuals^2), mean(model_23_train_residuals^2), mean(model_24_train_residuals^2), mean(model_25_train_residuals^2),
                mean(model_26_train_residuals^2), mean(model_27_train_residuals^2), mean(model_28_train_residuals^2), mean(model_29_train_residuals^2), mean(model_30_train_residuals^2),
                mean(model_31_train_residuals^2), mean(model_32_train_residuals^2), mean(model_33_train_residuals^2), mean(model_34_train_residuals^2), mean(model_35_train_residuals^2))
      )

goodness_of_fit %>% 
  set_number_format(col=c(2,3,4,5), value=3) %>%
  set_bottom_border(c(1,11,14), everywhere) %>%
  set_bold(c(2,4,5,6,12,13), everywhere) %>%
  set_background_color(c(2,4,5,6,12,13), everywhere, "grey95")
```

\newpage

 .

\newpage

## Model Selection

```{r}
model_21_train_forecast<- sarima.for(Avg_ExtentTS_Train, n.ahead=22, p=1,d=0,q=1,P=0,D=1,Q=1,S=12)
lines(Avg_ExtentTS_Test,col='blue',type='b',pch=16)
model_23_train_forecast<- sarima.for(Avg_ExtentTS_Train, n.ahead=22, p=1,d=0,q=1,P=0,D=1,Q=3,S=12)
lines(Avg_ExtentTS_Test,col='blue',type='b',pch=16)
model_24_train_forecast<- sarima.for(Avg_ExtentTS_Train, n.ahead=22, p=1,d=0,q=1,P=0,D=1,Q=4,S=12)
lines(Avg_ExtentTS_Test,col='blue',type='b',pch=16)
model_25_train_forecast<- sarima.for(Avg_ExtentTS_Train, n.ahead=22, p=1,d=0,q=1,P=1,D=1,Q=1,S=12)
lines(Avg_ExtentTS_Test,col='blue',type='b',pch=16)

mean((model_21_train_forecast$pred-Avg_ExtentTS_Test)^2)
mean((model_23_train_forecast$pred-Avg_ExtentTS_Test)^2)
mean((model_24_train_forecast$pred-Avg_ExtentTS_Test)^2)
mean((model_25_train_forecast$pred-Avg_ExtentTS_Test)^2)
```